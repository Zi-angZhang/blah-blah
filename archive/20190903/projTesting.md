# 实验、结果、分析



# 数据准备

### 图像降质量模型

#### JPEG 压缩

原始图像经常被以JPEG格式压缩保存下来。由于JPEG压缩方式在图像块中使用有损压缩(lossy compression)，在丢失图像高频信息的同时，还会引入肉眼可见的块效应，极大影响观赏体验。



JEPG压缩过程具有质量参数Q可以调整压缩比和输出图像的质量，质量参数Q越小，压缩比越高，图像体积越小，图像质量越差，图像块效应越明显。通常质量参数Q的取值范围是[0, 100]。考虑真实场景需要处理的图像的多样性，我们使用Q=100 和Q=80来模拟相机直出和高清晰度的图像，使用Q=30 和Q=10 模拟高压缩比或经历多次压缩的JPEG图像。



我们的实验工具是`openCV-python`，核心压缩代码是

``` python
cv2.imwrite(join(targetFolder, imgName.replace('bmp', 'jpg')), img, [cv2.IMWRITE_JPEG_QUALITY, quality])
```

[dct](https://blog.csdn.net/timebomb/article/details/5960624)



#### 噪声

图像的获取、传输和储存都可能给图像引入噪声。目前，图像噪声大致可以分为高斯噪声和椒盐噪声两种，图像噪声往往会掩盖图像传达的准确信息。

普遍的热噪声、起伏噪声都可以被认为是高斯噪声。高斯噪声的数值满足均值为0的高斯分布，高斯噪声的方差越大，图像上的噪点越明显，图像观感越差。椒盐噪声来源于数字成像系统像素的随机反转，通常用异常像素占总像素的比重来衡量椒盐噪声的强度

考虑到不同等级的噪声污染和噪声种类，我们通过在高清图像上添加方差为15、25、35的正态分布随机矩阵模拟高斯噪声污染的图像，对高清图像以0.0002、0.00002的比例随机反转像素模拟椒盐噪声污染的图像进行实验。

我们的实验工具是`openCV-python, numpy`，核心代码是

```python
#高斯噪声
noisy = img + numpy.random.normal(mean,sigma, (w, h, c))
#椒盐噪声
noisy = np.copy(img)
coordSalt = [np.random.randint(0, i-1, int(amount/2)) for i in img.shape]
noisy[coordSalt] = 0 
coordPepper = [np.random.randint(0, i-1, int(amount/2)) for i in img.shape]
noisy[coordPepper] = 255
```



#### 下采样

图像的下采样往往发生在图像的获取过程和储存过程中，由于成像设备或储存空间限制，图像丢失了部分像素的信息尤其是高频信息。

一般的图像下采样由下采样倍率控制，比如2倍的下采样会使4k分辨率的图像在长和宽两个维度缩减为原来的一半，像素数量为原始图像的1/4，变成2k图像。常规的下采样模拟方法是双三插值下采样。

由于我们的图像处理对象为高清图像，过高的上采样需求并不常见，因而我们只做2倍的下采样。

我们的实验工具是`openCV-python`，核心代码是

```python
imgDown = cv2.resize(img, (0,0), fx=1/scale, fy = 1/scale)
```



#### 高斯模糊

成像系统在散焦时无法清晰成像，这种行为往往可以用高斯模糊表示。

高斯模糊的本质是一个低通滤波，我们可以通过控制卷积滤波核的大小控制高斯模糊的程度。为了体现不同程度的模糊，我们分别使用大小为5、9、 13的高斯核生成高斯模糊的图像。

我们的实验工具是`openCV-python`，核心代码是

```python
imgDown = cv2.GaussianBlur(img, (size, size), cv2.BORDER_DEFAULT)
```



#### 丢帧

成像系统的采样率不足会导致视频缺少关键帧从而造成视觉上的卡顿。我们可以从高帧率的视频中删除关键帧来模拟低采样率视频。

考虑到计算量以及实际需求，我们在图像序列中每隔一帧删除掉一个关键帧实现丢帧的模拟。



## 图像增强方法

### 常规图像增强介绍（对照组）

##### 去噪

###### 非局部均值滤波(Non-local means filtering)

非局部均值滤波能够利用全局的荣誉信息，有比传统局部方法（平滑滤波、双边滤波）更强的保留细节的能力。非局部均值滤波搜索全局区域具有较高相似度的图像块，随后将区域求均值后再对加权平均得到目标像素值，因而可以高效地滤除高斯噪声。

###### 三维块匹配滤波(Block-matching and 3D filtering)

将图像中的相似块堆叠成三维矩阵随后对该三维矩阵进行协同滤波和聚合，充分挖掘图像中的冗余信息，实现保留细节的同时去除高斯噪声。但由于其极高的计算复杂度，难以实现图像的实时去噪。



##### 超分辨

###### 双三次插值(Bicubic interpolation)

双三次插值利用图像的连续性先验，快速实现图像的指定尺度放大。由于其计算高效被广泛应用。但其对图像连续性的假设会使输出图像趋向模糊。

###### 卷积神经网络超分辨(SRCNN)

利用卷积神经网络学习低分辨率图像到高分辨率图像的直接映射，端到端提升图像的分辨率。具有三层卷积神经网络。

###### 深度卷积超分辨(VDSR)

利用残差结构学习低分辨率图像到高分辨率图像的直接映射，端到端实现图像超分辨率。具有20层卷积神经网络。



##### 去块

###### h.264去块滤波

使用滤波器在块的边界平滑滤波，具有在梯度较小区域滤波效果强，在梯度较大区域滤波效果弱的特点



##### 去模糊





### 先进图像增强（实验组）

##### 去噪

 ###### 基于残差学习的去噪深度卷积神经网络(DnCNN)

DnCNN利用残差学习的结构设计网络，通过叠加20个卷积-批归一化-线性整流模块组成非线性映射，实现对输入图像到噪声张量的估计。在训练时可对无噪声的图像统一加入特定方差的高斯噪声作为输入，具有细节保留效果好、去噪效果强和端到端的优点。

DnCNN可以在对不同等级的噪声预测时调用相对应的训练模型。

相应研究成果在IEEE Transactions on Image Processing 2017发表。

###### 快速可调节去噪卷积神经网络(FFDNet)

考虑到实时处理高清图像，并且应对多种程度噪声的需求，我们设计快速可调节去噪卷积神经网络(FFDNet)，在网络的输入端和输出端分别施加无损失的下采样和上采样，减小特征张量的长宽尺度，从而降低计算复杂度。此外快速可调节去噪神经网络能够接受噪声估计作为输入，从而在一个训练完成的模型中实现对不同强度的噪声的去除。

FFDNet具有噪声等级调节参数，在实验时，我们对不同噪声等级使用对应参数进行预测。

相应研究成果在IEEE Transactions on Image Processing 2018发表。

##### 超分辨

###### 基于迭代收缩阈值的图像压缩感知重建网络(ISTA-Net)

低分辨率图像可以被视为高清图像的压缩感知采样，因而从低清图像到高清图像的映射是一个压缩感知重建问题。我们借鉴了传统优化器迭代重建方法的对图像结构的理解，并将其与高效的神经网络结构结合，实现了与稀疏引导正则化相关的高效近端映射。

ISTA-Net的所有参数是可学习参数，能够端到端地完成训练。

相应研究成果在CVPR2018发表。



## 评估方法

### 量化评估

#### 峰值信噪比(Share
Peak Signal-to-noise Ratio, PSNR)



#### 结构相似性(Structural similarity, SSIM)



#### 特征相似性(Feature Similarity, FSIM)



## 比对结果

### 量化结果

### 结果示例



